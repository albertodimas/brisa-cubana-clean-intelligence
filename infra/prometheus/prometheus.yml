# Prometheus Configuration for Brisa Cubana Clean Intelligence
# References:
# - Prometheus Configuration: https://prometheus.io/docs/prometheus/latest/configuration/configuration/
# - Scraping Best Practices: https://prometheus.io/docs/practices/instrumentation/
# Consulted: October 2, 2025

global:
  scrape_interval: 15s # Scrape targets every 15 seconds (default)
  scrape_timeout: 10s # Timeout after 10s
  evaluation_interval: 15s # Evaluate recording/alerting rules every 15 seconds

  # Attach these labels to any time series scraped
  external_labels:
    cluster: 'brisa-production'
    environment: 'production'

# Alertmanager configuration (optional - for production alerts)
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093 # Update with actual Alertmanager endpoint

# Load recording/alerting rules from files
rule_files:
  - 'alerts/*.yml'
  - 'recording_rules/*.yml'

# Scrape configurations
scrape_configs:
  # ===========================================================================
  # API Service (Railway Deployment)
  # ===========================================================================
  - job_name: 'brisa-api'
    scrape_interval: 10s # More frequent for API metrics
    static_configs:
      - targets:
          - 'api.brisacubana.com:9464' # OpenTelemetry Prometheus exporter port
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'brisa-api'
    metric_relabel_configs:
      # Drop noisy metrics
      - source_labels: [__name__]
        regex: 'go_.*|process_.*' # Drop Go runtime metrics (not applicable for Node.js)
        action: drop

  # ===========================================================================
  # Web Service (Vercel Deployment) - via Vercel Analytics API
  # ===========================================================================
  # Note: Vercel provides built-in analytics, but for custom metrics:
  # - job_name: 'brisa-web'
  #   static_configs:
  #     - targets:
  #         - 'brisacubana.com:9464'

  # ===========================================================================
  # PostgreSQL Database (Neon/Supabase)
  # ===========================================================================
  - job_name: 'postgres-exporter'
    scrape_interval: 30s
    static_configs:
      - targets:
          - 'postgres-exporter:9187' # postgres_exporter (deploy separately)
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'brisa-postgres'

  # ===========================================================================
  # Redis Cache (if applicable)
  # ===========================================================================
  - job_name: 'redis-exporter'
    scrape_interval: 30s
    static_configs:
      - targets:
          - 'redis-exporter:9121' # redis_exporter (deploy separately)
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'brisa-redis'

  # ===========================================================================
  # Self-monitoring (Prometheus itself)
  # ===========================================================================
  - job_name: 'prometheus'
    static_configs:
      - targets:
          - 'localhost:9090'

# ===========================================================================
# Storage Configuration
# ===========================================================================
# Remote write (optional - for long-term storage in Grafana Cloud, Mimir, etc.)
# remote_write:
#   - url: 'https://prometheus-prod-10-prod-us-central-0.grafana.net/api/prom/push'
#     basic_auth:
#       username: 'your_username'
#       password: 'your_api_key'

# Storage retention (local Prometheus)
# Configured via command-line flags:
# --storage.tsdb.retention.time=30d (keep 30 days of data)
# --storage.tsdb.retention.size=50GB (or limit by size)
